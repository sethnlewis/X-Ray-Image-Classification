{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Klbx-ZHs0D4b"
   },
   "source": [
    "## Introduction\n",
    "The purpose of this analysis is to design a model that can use chest x-ray images to identify pneumonia. According to the American Thoracic Society, pneumonia is the [leading cause of death](https://www.thoracic.org/patients/patient-resources/resources/top-pneumonia-facts.pdf) among children under age 5, accounting for roughly 16% of all deaths within that age range in 2015. The application of machine learning techniques such as neural networks can help identify the presence of pneumonia using exclusively chest x-rays. \n",
    "\n",
    "\n",
    "### Data Sources\n",
    "The data used in this analysis was original provided by Mendeley Data and is publicly available [here](https://data.mendeley.com/datasets/rscbjbr9sj/3) (1). The dataset was subsequently adapted to a Kaggle dataset, which can be found [here](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).\n",
    "\n",
    "In total, 5856 X-ray images in jpeg format are provided. Each is already labeled to indicate whether or not pneumonia is present.\n",
    "\n",
    "### The Process\n",
    "\n",
    "This analysis will follow the general structure listed here:\n",
    "1. Import packages and data\n",
    "2. Function definitions\n",
    "3. Modeling\n",
    "4. Evaluation\n",
    "5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5BPEocj0D4e"
   },
   "source": [
    "## Part 1. Import packages and data\n",
    "\n",
    "##### Package Imports\n",
    "The below packages are necessary for various functionality throughout the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:14:42.285630Z",
     "iopub.status.busy": "2021-07-08T01:14:42.285213Z",
     "iopub.status.idle": "2021-07-08T01:14:47.182859Z",
     "shell.execute_reply": "2021-07-08T01:14:47.181926Z",
     "shell.execute_reply.started": "2021-07-08T01:14:42.285537Z"
    },
    "id": "ub7afhhI0D4f"
   },
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys, os\n",
    "\n",
    "# Use Scikit-learn for train-test splits and model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "# Import various Keras/Tensorflow packages for neural networks\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "# Global static variable declarations\n",
    "RANDOM_STATE = 2020 # Ensure repeatable results\n",
    "VAL_SPLIT = 0.25 # Use 25% of data for validation and test splits\n",
    "\n",
    "# Set resolution of each photo. Each image downsampled this pixel ct\n",
    "TARGET_SIZE = 128\n",
    "\n",
    "# Path \"images\" folder\n",
    "IMG_PATH = '../images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIeB6UVR0D4g"
   },
   "source": [
    "##### Operating platform selection\n",
    "Since this project has been run using local CPUs in addition to the GPUs offered by Google Colab and Kaggle Notebooks, the below cell quickly enables to user to select the platform of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:14:47.184728Z",
     "iopub.status.busy": "2021-07-08T01:14:47.184376Z",
     "iopub.status.idle": "2021-07-08T01:14:47.194458Z",
     "shell.execute_reply": "2021-07-08T01:14:47.193652Z",
     "shell.execute_reply.started": "2021-07-08T01:14:47.184690Z"
    },
    "id": "Dj3wBdeR0D4g"
   },
   "outputs": [],
   "source": [
    "# Set 'platform' to any of the following: \"kaggle\", \"colab\", \"local\" depending \n",
    "# on use case\n",
    "platform = 'local'\n",
    "\n",
    "\n",
    "\n",
    "def set_data_path(platform):\n",
    "    \"\"\" \n",
    "    Since this project has been run using local CPUs in addition\n",
    "    to the GPUs offered by Google Colab and Kaggle Notebooks, \n",
    "    this function quickly enables to user to select the \n",
    "    platform of choice\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    platform : string containing \"kaggle\", \"colab\", or \"local\"\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    path_train : string showing path to training images\n",
    "    path_val : string showing path to validation images\n",
    "    path_test: string showing path to test images\n",
    "\n",
    "    \"\"\"    \n",
    "    # Set file paths if running on Kaggle notebook\n",
    "    if platform == 'kaggle':\n",
    "        path_train = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train/'\n",
    "        path_val   = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/'\n",
    "        path_test  = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test/'\n",
    "    \n",
    "    # Set file paths if running on Google Colab\n",
    "    elif platform == 'colab':\n",
    "        path_train = '/content/drive/MyDrive/Data Science/Colab Notebooks/Module 4 Project/data/raw/train'\n",
    "        path_val   = '/content/drive/MyDrive/Data Science/Colab Notebooks/Module 4 Project/data/raw/val'\n",
    "        path_test  = '/content/drive/MyDrive/Data Science/Colab Notebooks/Module 4 Project/data/raw/test'\n",
    "        \n",
    "        # Notebook must be \"mounted\" to access stored data files\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "    # Set file paths if running locally\n",
    "    elif platform == 'local':\n",
    "        path_train = '../data/raw/train'\n",
    "        path_val = '../data/raw/val'\n",
    "        path_test  = '../data/raw/test'\n",
    "\n",
    "    else:\n",
    "        sys.exit('ERROR: PLEASE ENTER \"kaggle\", \"colab\" or \"local\"')\n",
    "    \n",
    "    return path_train, path_val, path_test\n",
    "\n",
    "\n",
    "# Run function to set data paths for the platform being used\n",
    "path_train, path_val, path_test = set_data_path(platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QsySh5L0D4h"
   },
   "source": [
    "#### Data Imports\n",
    "It has been made clear through external research that substantial data within the provided Test dataset has been mislabeled. As a result, a model cannot effectively predict correctly when trained on correctly labeled data. To address the issue, data from both Train and Test folders are imported, combined, then randomly split within this notebook. This minimizes the impact of mislabeled data and in turn creates a model that is more generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znvB3Rtu0D4j"
   },
   "source": [
    "##### Create function to import all images from provided directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:14:47.198210Z",
     "iopub.status.busy": "2021-07-08T01:14:47.197950Z",
     "iopub.status.idle": "2021-07-08T01:14:47.207113Z",
     "shell.execute_reply": "2021-07-08T01:14:47.206291Z",
     "shell.execute_reply.started": "2021-07-08T01:14:47.198185Z"
    },
    "id": "BBMceha50D4j"
   },
   "outputs": [],
   "source": [
    "def import_data(path, file_ct, res=TARGET_SIZE):\n",
    "    \"\"\" \n",
    "    Import images and labels from input directory using\n",
    "    ImageDataGenerator functionality. Output data as arrays.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : string containing file path to data\n",
    "    file_ct : number of files contained within directory\n",
    "    res : resolution of images (downsampled from original)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    images : numpy array representing images in directory\n",
    "    labels : numpy array with labels for above images\n",
    "\n",
    "    \"\"\"    \n",
    "        \n",
    "        \n",
    "    # Instantiate Keras generator, scaling all RGB inputs from the \n",
    "    # default [0, 255] range to the [0, 1] range since neural \n",
    "    # network inputs should be normalized\n",
    "    generator = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "    # Create flow object to bring images from folders to memory\n",
    "    gen_train = generator.flow_from_directory(directory=path, \n",
    "                                              target_size=(res, res), \n",
    "                                              batch_size=file_ct, \n",
    "                                              seed=RANDOM_STATE)\n",
    "    # Store all images in numpy array\n",
    "    data_and_labels = next(gen_train)\n",
    "\n",
    "    \n",
    "    return data_and_labels[0], data_and_labels[1] # images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBDC-21o0D4k"
   },
   "source": [
    "##### Run the above-defined function\n",
    "Create datasets and aggregate them into one final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:14:47.209468Z",
     "iopub.status.busy": "2021-07-08T01:14:47.208853Z",
     "iopub.status.idle": "2021-07-08T01:16:21.120220Z",
     "shell.execute_reply": "2021-07-08T01:16:21.119260Z",
     "shell.execute_reply.started": "2021-07-08T01:14:47.209427Z"
    },
    "id": "ttG10--T0D4l",
    "outputId": "21b44c49-1f82-4b27-a926-4b88bdb352c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Image data shape: (5856, 128, 128, 3)\n",
      "Label data shape: (5856, 2)\n"
     ]
    }
   ],
   "source": [
    "# Number of images in selected folder\n",
    "# (NORMAL + PNEUMONIA)\n",
    "file_ct_train = 1349 + 3883\n",
    "file_ct_val = 8 + 8\n",
    "file_ct_test = 234 + 390\n",
    "\n",
    "# Run above-defined function for each of the datasets\n",
    "images, labels = import_data(path_train, file_ct_train)\n",
    "images_val, labels_val = import_data(path_val, file_ct_val)\n",
    "images_test, labels_test = import_data(path_test, file_ct_test)\n",
    "\n",
    "# Aggregate all datasets into one for inputs and one for outputs\n",
    "images = np.concatenate([images, images_val, images_test], axis=0)\n",
    "labels = np.concatenate([labels, labels_val, labels_test], axis=0)\n",
    "\n",
    "# Remove unnecessary data to prevent memory shortages\n",
    "del images_val, labels_val\n",
    "del images_test, labels_test\n",
    "\n",
    "# For data understanding. Verify images are imported as expected\n",
    "print('Image data shape:', images.shape)\n",
    "print('Label data shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FXRfrmG0D4m"
   },
   "source": [
    "##### Perform a train-test split on all data\n",
    "\n",
    "As mentioned above, there is reason to believe that the splits provided by the dataset publishers may be flawed. As a result, the below cell creates a split into training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:21.121996Z",
     "iopub.status.busy": "2021-07-08T01:16:21.121637Z",
     "iopub.status.idle": "2021-07-08T01:16:22.259237Z",
     "shell.execute_reply": "2021-07-08T01:16:22.258324Z",
     "shell.execute_reply.started": "2021-07-08T01:16:21.121956Z"
    },
    "id": "FMYbQbdi0D4m"
   },
   "outputs": [],
   "source": [
    "# Classic train-test split for TEST data\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, \n",
    "                                                  random_state=RANDOM_STATE, \n",
    "                                                  test_size=VAL_SPLIT)\n",
    "\n",
    "# Classic train-test split for VALIDATION data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
    "                                                  random_state=RANDOM_STATE, \n",
    "                                                  test_size=VAL_SPLIT)\n",
    "\n",
    "\n",
    "# Remove unnecessary data to prevent memory shortages\n",
    "del images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shC2Ej4s0D4m"
   },
   "source": [
    "## Step 2. Function definitions\n",
    "\n",
    "Now that data has been imported, split and analyzed, the notebook soon proceeds to the modeling stage. However, first, valuable functions are defined to enable easier, consistent analysis of subsequent model iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2flbcJ20D4m"
   },
   "source": [
    "##### Define function to plot the performance of selected model across epoch iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:22.261037Z",
     "iopub.status.busy": "2021-07-08T01:16:22.260672Z",
     "iopub.status.idle": "2021-07-08T01:16:22.268878Z",
     "shell.execute_reply": "2021-07-08T01:16:22.267776Z",
     "shell.execute_reply.started": "2021-07-08T01:16:22.261001Z"
    },
    "id": "f_qdAU4q0D4n"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history, metrics=['accuracy'], \n",
    "                 val=True, plot_path=False):\n",
    "\n",
    "    \"\"\" \n",
    "    Creates graphs of neural network performance across a range of \n",
    "    epochs. \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    history : 'history' attribute of a model fit object\n",
    "    metrics : list of metrics to be plotted\n",
    "    val : whether or not model was fit with validation data\n",
    "    plot_path : file path to save plots\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "\n",
    "    \"\"\"    \n",
    "    \n",
    "    \n",
    "    # Create one plot for each metric being analyzed\n",
    "    for metric in metrics:\n",
    "        \n",
    "        # Normalize casing to reduce possible errors\n",
    "        metric=str.lower(metric)\n",
    "        \n",
    "        # Define 'x' variable according to the number of epochs\n",
    "        x = range(len(history[metric]))\n",
    "\n",
    "        # Create figure and plot the metric\n",
    "        plt.figure()\n",
    "        plt.plot(x, history[metric], label='Train')\n",
    "\n",
    "        # If a validation split was used, plot its performance\n",
    "        if val:\n",
    "            plt.plot(x, history['val_'+metric], label='Validation')\n",
    "        \n",
    "        # Basic figure improvements\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.title(metric)\n",
    "        plt.legend()\n",
    "        \n",
    "        if plot_path:\n",
    "            plt.savefig(plot_path+\"_\"+metric+\".png\")            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oC_rqLIR0D4n"
   },
   "source": [
    "##### Define function to plot the confusion matrices for selected models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:22.270897Z",
     "iopub.status.busy": "2021-07-08T01:16:22.270302Z",
     "iopub.status.idle": "2021-07-08T01:16:22.285170Z",
     "shell.execute_reply": "2021-07-08T01:16:22.284286Z",
     "shell.execute_reply.started": "2021-07-08T01:16:22.270855Z"
    },
    "id": "4ZCp0Ak80D4n"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(model, images, labels, plot_path):\n",
    "    \n",
    "    \"\"\" \n",
    "    Show a confusion matrix for the output of a neural network\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : keras model, prefit\n",
    "    images : data used to fit model\n",
    "    plot_path : file path used to save confusion matrix image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    matrix : confusion matrix as numpy array\n",
    "    matrix_norm : normalized confusion matrix as numpy array\n",
    "\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Reformat \"Labels\" data for easier Confusion Matrix use\n",
    "    truth = (labels[:, 1]==1).astype('int')\n",
    "    \n",
    "    # Predict Labels using the inputted model\n",
    "    preds = np.argmax(model.predict(images), axis=-1)\n",
    "\n",
    "    # Instantiate confusion matrix, NOT normalized\n",
    "    matrix = confusion_matrix(truth, preds, normalize='false')\n",
    "    ConfusionMatrixDisplay(matrix).plot()\n",
    "    plt.xticks(ticks = [0, 1], labels=['No pneumonia', 'Pneumonia'])\n",
    "    plt.yticks(ticks = [0, 1], labels=['No pneumonia', 'Pneumonia'])\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.title('Correctness of Model Predictions (COUNT)');\n",
    "\n",
    "    if plot_path:\n",
    "        plt.savefig(plot_path+\"_count.png\")\n",
    "    \n",
    "    # Instantiate confusion matrix, NORMALIZED\n",
    "    matrix_norm = confusion_matrix(truth, preds, normalize='true')\n",
    "    ConfusionMatrixDisplay(matrix_norm).plot()\n",
    "    plt.xticks(ticks = [0, 1], labels=['No pneumonia', 'Pneumonia'])\n",
    "    plt.yticks(ticks = [0, 1], labels=['No pneumonia', 'Pneumonia'])\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.title('Correctness of Model Predictions (%)')\n",
    "    \n",
    "    if plot_path:\n",
    "        plt.savefig(plot_path+\"_percent.png\")\n",
    "    \n",
    "    return matrix, matrix_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6UxNgBb0D4o"
   },
   "source": [
    "##### Define top-level function to aggregate the previously-defined two functions, in addition to printing several performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:22.288450Z",
     "iopub.status.busy": "2021-07-08T01:16:22.288069Z",
     "iopub.status.idle": "2021-07-08T01:16:22.299439Z",
     "shell.execute_reply": "2021-07-08T01:16:22.298640Z",
     "shell.execute_reply.started": "2021-07-08T01:16:22.288392Z"
    },
    "id": "ZUcFFZsZ0D4o"
   },
   "outputs": [],
   "source": [
    "def acc_pre_rec_f1(truth, pred):\n",
    "    \"\"\" \n",
    "    Format and print standard performance metrics\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    truth : 'true' values\n",
    "    pred : 'predicted' values\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "\n",
    "    \"\"\"    \n",
    "    \n",
    "    print('Accuracy:', round(accuracy_score(truth, pred), 4)*100, \"%\")\n",
    "    print('Precision:', round(precision_score(truth, pred), 4)*100, \"%\")\n",
    "    print('Recall:', round(recall_score(truth, pred), 4)*100, \"%\")\n",
    "    print('F1 score:', round(f1_score(truth, pred), 4)*100, \"%\");\n",
    "\n",
    "\n",
    "\n",
    "def show_model_performance(model, x_val, y_val, fit=False, \n",
    "                           plot_path=False):\n",
    "    \"\"\" \n",
    "    Top-level function to aggregate previously-defined performance \n",
    "    functions, in addition to printing several performance metrics. \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : keras model, prefit\n",
    "    x_val : numpy array for validation data, input\n",
    "    y_val : numpy array for validation data, output\n",
    "    fit : boolean indicating whether or not to plot the \"fit\" process\n",
    "    plot_path : file path used to metrics/epochs plot image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "\n",
    "    \"\"\"    \n",
    "    \n",
    "    if fit:\n",
    "        plot_metrics(fit.history, plot_path = plot_path)\n",
    "    \n",
    "    show_confusion_matrix(model, x_val, y_val, plot_path)\n",
    "    display(model.summary())\n",
    "    \n",
    "    # Reformat \"Labels\" data for easier Confusion Matrix use\n",
    "    truth = (y_val[:, 1]==1).astype('int')\n",
    "    \n",
    "    # Predict Labels using the inputted model\n",
    "    preds = np.argmax(model.predict(x_val), axis=-1)\n",
    "\n",
    "    # Print performance metrics\n",
    "    acc_pre_rec_f1(truth, preds);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NECHtjOo0D4o"
   },
   "source": [
    "##### Instantiate and define callbacks and commonly used variables\n",
    "\n",
    "#### Callbacks\n",
    "- The EarlyStopping callback to eliminate the need for tuning the number of epochs used in a model. This way, the model can run until it has reached its maximum performance without wasting computational power. \n",
    "- The ModelCheckpoint callback is used to select the top-performing model over the full range of epochs used for each model training. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:22.301909Z",
     "iopub.status.busy": "2021-07-08T01:16:22.301476Z",
     "iopub.status.idle": "2021-07-08T01:16:22.312316Z",
     "shell.execute_reply": "2021-07-08T01:16:22.311464Z",
     "shell.execute_reply.started": "2021-07-08T01:16:22.301867Z"
    },
    "id": "sMJUT_Ye0D4o"
   },
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(monitor='val_loss', \n",
    "                              patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmXHx5Wa0D4o"
   },
   "source": [
    "#### Input shape\n",
    "Define the shape of the input data that will be used throughout each of the subsequent models based on the resolution of the downsampled input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:22.313898Z",
     "iopub.status.busy": "2021-07-08T01:16:22.313546Z",
     "iopub.status.idle": "2021-07-08T01:16:22.322910Z",
     "shell.execute_reply": "2021-07-08T01:16:22.321888Z",
     "shell.execute_reply.started": "2021-07-08T01:16:22.313863Z"
    },
    "id": "hm0_cpXG0D4p"
   },
   "outputs": [],
   "source": [
    "input_shape = (TARGET_SIZE, TARGET_SIZE, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9CRCaNL0D4p"
   },
   "source": [
    "## Step 3. Modeling\n",
    "\n",
    "Using the Keras *Sequential* model, the below models investigate combinations of various layer combinations, node counts, and normalizations to find the best performance. Note that for the purpose of this analysis, there was insufficient computational power to perform extensive grid searches of hyperparameters, as would be needed to fully optimize each model. Instead, research-backed estimates of high-performing hyperparameter combinations are made. Future improvements would include exhaustive hyperparameter optimization, but that will be left for future analyses with more computational resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ll92strc0D4p"
   },
   "source": [
    "##### The Baseline Model\n",
    "The baseline performance shows the performance of a *random guess* methodology, which can be helpful when first developing a model. It allows the question to be answered, *does the model actually provide any value?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:22.324778Z",
     "iopub.status.busy": "2021-07-08T01:16:22.324259Z",
     "iopub.status.idle": "2021-07-08T01:16:22.354296Z",
     "shell.execute_reply": "2021-07-08T01:16:22.353250Z",
     "shell.execute_reply.started": "2021-07-08T01:16:22.324741Z"
    },
    "id": "zOgfc0f60D4p",
    "outputId": "bac92f9f-38b5-4620-b18c-c8ce3589017a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BASELINE performance on validation data:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6bac3d84cddf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Print performance metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nBASELINE performance on validation data:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0macc_pre_rec_f1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Define baseline model function\n",
    "def baseline_model(y):\n",
    "    \"\"\" \n",
    "    Basic model to provide an array of random binary\n",
    "    numbers of the same size as the input\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y : data on which to base prediction, numpy array\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    preds : predicted model values, numpy array\n",
    "\n",
    "    \"\"\"  \n",
    "    \n",
    "    \n",
    "    random_choice = lambda x: np.random.choice([0, 1])\n",
    "    preds_map = map(random_choice, y[:, 1])\n",
    "    preds = np.array(list(preds_map))\n",
    "    return preds\n",
    "\n",
    "\n",
    "# Create predictions using model function\n",
    "preds = baseline_model(y_val)\n",
    "truth = y_val[:, 1]\n",
    "\n",
    "\n",
    "# Print performance metrics\n",
    "print('\\nBASELINE performance on validation data:')\n",
    "acc_pre_rec_f1(truth, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Gm-4G1y0D4q"
   },
   "source": [
    "##### The First Simple Model\n",
    "Define the FSM using only one Dense layer with two nodes. This model flattens the input data and subsequently applies the one additional layer within nearly hyperparameters set to the default.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:22.356255Z",
     "iopub.status.busy": "2021-07-08T01:16:22.355805Z",
     "iopub.status.idle": "2021-07-08T01:16:52.583376Z",
     "shell.execute_reply": "2021-07-08T01:16:52.582444Z",
     "shell.execute_reply.started": "2021-07-08T01:16:22.356218Z"
    },
    "id": "5t5l-AhT0D4q",
    "outputId": "10a31110-eae9-429f-f7a1-bc27caca41d3"
   },
   "outputs": [],
   "source": [
    "# Instantiate sequential model\n",
    "model_fsm = Sequential()\n",
    "\n",
    "# Flatten input data\n",
    "model_fsm.add(Flatten())\n",
    "\n",
    "# Add Dense layer for activation\n",
    "model_fsm.add(Dense(2, activation='softmax', \n",
    "             input_shape=input_shape))\n",
    "\n",
    "# Compile model\n",
    "model_fsm.compile(optimizer='SGD', \n",
    "                  metrics=['accuracy'], \n",
    "                  loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "# Define path to save model to\n",
    "path_model = 'tmp/model_fsm.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "    \n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit_fsm = model_fsm.fit(x=x_train, \n",
    "                        y=y_train, \n",
    "                        epochs=500,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[early_stopper, check],\n",
    "                        verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model_fsm.load_weights(path_model)\n",
    "\n",
    "# Call function to output performance specs and graphs\n",
    "show_model_performance(model_fsm, x_val, y_val, fit_fsm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzcGKL3x0D4q"
   },
   "source": [
    "#### Add convolutional layer to previous model\n",
    "\n",
    "Given an awareness that Convolutional Neural Networks (CNNs) are often top performing models for image classification, the below model adds a 2D convolutional layer to the previous model. The node count, kernel size and activation function were based on simple testing. Recall that there was insufficient computational power to perform grid searches of hyperparameters, as would be needed to fully optimize each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:16:52.585101Z",
     "iopub.status.busy": "2021-07-08T01:16:52.584739Z",
     "iopub.status.idle": "2021-07-08T01:17:55.936073Z",
     "shell.execute_reply": "2021-07-08T01:17:55.935045Z",
     "shell.execute_reply.started": "2021-07-08T01:16:52.585063Z"
    },
    "id": "5rgKmVXS0D4q",
    "outputId": "acaaccee-e47a-4007-e258-7e3b6f1f4608"
   },
   "outputs": [],
   "source": [
    "# Instantiate sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer with 32 nodes\n",
    "model.add(Conv2D(32, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "\n",
    "# Flatten input data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layer for activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='SGD',\n",
    "              metrics=['accuracy'], \n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "# Define path to save model to\n",
    "path_model = 'tmp/model_2.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "    \n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit = model.fit(x=x_train, \n",
    "                y=y_train,\n",
    "                epochs=500,\n",
    "                callbacks=[early_stopper, check],\n",
    "                validation_data=(x_val, y_val),\n",
    "                verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model.load_weights(path_model)\n",
    "\n",
    "# Call function to output performance specs and graphs\n",
    "show_model_performance(model, x_val, y_val, fit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwOdHl3I0D4q"
   },
   "source": [
    "##### Increase node count substantially\n",
    "Looking at the above accuracy plots over a range of epochs, the is clear that the model has a relatively low accuracy relative to a wide range of testing in the EDA phase of this project. Accordingly, additional nodes are added to the Convolutional layer of the below model to create a more tunable model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:17:55.938282Z",
     "iopub.status.busy": "2021-07-08T01:17:55.937841Z",
     "iopub.status.idle": "2021-07-08T01:20:26.404257Z",
     "shell.execute_reply": "2021-07-08T01:20:26.403338Z",
     "shell.execute_reply.started": "2021-07-08T01:17:55.938217Z"
    },
    "id": "FZ-RMJSo0D4r",
    "outputId": "02d92884-8293-4931-cd55-a6741f63f069"
   },
   "outputs": [],
   "source": [
    "# Instantiate sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer with 64 nodes\n",
    "model.add(Conv2D(64, activation='relu',\n",
    "                 kernel_size=11,  \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "\n",
    "# Flatten input data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layer for activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='SGD',\n",
    "              metrics=['accuracy'], \n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "# Define path to save model to\n",
    "path_model = 'tmp/model_3.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "    \n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit = model.fit(x=x_train, \n",
    "                y=y_train,\n",
    "                epochs=500,\n",
    "                callbacks=[early_stopper, check],\n",
    "                validation_data=(x_val, y_val),\n",
    "                verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model.load_weights(path_model)\n",
    "\n",
    "# Call function to output performance specs and graphs\n",
    "show_model_performance(model, x_val, y_val, fit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBDckIAO0D4r"
   },
   "source": [
    "##### Instead, increase depth with pooling\n",
    "As we can see, the accuracy actually decreased when adding extensive additional nodes. Instead of increasing the node count, we will return to a lower node count, and instead add an additional Convolutional layer, along with Pooling after each of the Convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:20:26.406054Z",
     "iopub.status.busy": "2021-07-08T01:20:26.405675Z",
     "iopub.status.idle": "2021-07-08T01:21:03.673049Z",
     "shell.execute_reply": "2021-07-08T01:21:03.672247Z",
     "shell.execute_reply.started": "2021-07-08T01:20:26.406013Z"
    },
    "id": "HcaZW_d-0D4r",
    "outputId": "1c31e246-954a-4431-b5fc-be584eb7ad8a"
   },
   "outputs": [],
   "source": [
    "# Instantiate sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer with 8 nodes\n",
    "model.add(Conv2D(8, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add convolutional layer with 16 nodes\n",
    "model.add(Conv2D(16, activation='relu',\n",
    "                 kernel_size=7,\n",
    "                 padding='same'))\n",
    "          \n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten input data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layer for activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='SGD',\n",
    "              metrics=['accuracy'], \n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "# Define path to save model to\n",
    "path_model = 'tmp/model_4.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "    \n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit = model.fit(x=x_train, \n",
    "                y=y_train,\n",
    "                epochs=500,\n",
    "                callbacks=[early_stopper, check],\n",
    "                validation_data=(x_val, y_val),\n",
    "                verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model.load_weights(path_model)\n",
    "\n",
    "# Call function to output performance specs and graphs\n",
    "show_model_performance(model, x_val, y_val, fit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkGOFva90D4r"
   },
   "source": [
    "##### Add one more Convolutional layer\n",
    "After seeing that the above additon of a layer increased all performance metrics, in addition to reducing overfitting, the below model takes it one step further by adding another Convolutional layer to investigate the impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:21:03.674849Z",
     "iopub.status.busy": "2021-07-08T01:21:03.674479Z",
     "iopub.status.idle": "2021-07-08T01:21:54.604451Z",
     "shell.execute_reply": "2021-07-08T01:21:54.603625Z",
     "shell.execute_reply.started": "2021-07-08T01:21:03.674811Z"
    },
    "id": "WN8f_ZcQ0D4s",
    "outputId": "eef13343-f768-4dd1-af2a-b2bbb283f068"
   },
   "outputs": [],
   "source": [
    "# Instantiate sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer with 8 nodes\n",
    "model.add(Conv2D(8, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "# Add convolutional layer with 16 nodes\n",
    "model.add(Conv2D(16, activation='relu',\n",
    "                 kernel_size=7, \n",
    "                 padding='same'))\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "# Add convolutional layer with 32 nodes\n",
    "model.add(Conv2D(32, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 padding='same'))\n",
    "# Add pooling layer after convolutional     \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Flatten input data\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# Add Dense layer for activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='SGD',\n",
    "              metrics=['accuracy'], \n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "# Define path to save model to\n",
    "path_model = 'tmp/model_5.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "    \n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit = model.fit(x=x_train, \n",
    "                y=y_train,\n",
    "                epochs=500,\n",
    "                callbacks=[early_stopper, check],\n",
    "                validation_data=(x_val, y_val),\n",
    "                verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model.load_weights(path_model)\n",
    "\n",
    "# Call function to output performance specs and graphs\n",
    "show_model_performance(model, x_val, y_val, fit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mPDpHDt0D4s"
   },
   "source": [
    "##### Add Regularization to top performing Convolutional\n",
    "\n",
    "The additional layer above added accuracy and increased the F1 score relative to the previous model. However, it is still clear that there is overfitting. Regularization is a common solution for addressing overfitting. Accordingly, the below model adds L2 regularization to each Convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:21:54.607294Z",
     "iopub.status.busy": "2021-07-08T01:21:54.606933Z",
     "iopub.status.idle": "2021-07-08T01:23:18.743697Z",
     "shell.execute_reply": "2021-07-08T01:23:18.742890Z",
     "shell.execute_reply.started": "2021-07-08T01:21:54.607257Z"
    },
    "id": "ppcfwOXe0D4s",
    "outputId": "e409da1e-ee0e-433b-d138-80e9a2702cee"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter for L2 regularization\n",
    "LAMBDA = 0.005\n",
    "\n",
    "# Instantiate sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer with 8 nodes\n",
    "model.add(Conv2D(8, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(LAMBDA)))\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Add convolutional layer with 16 nodes\n",
    "model.add(Conv2D(16, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(LAMBDA)))\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Add convolutional layer with 32 nodes\n",
    "model.add(Conv2D(32, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(LAMBDA)))\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten input data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layer for activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='SGD',\n",
    "              metrics=['accuracy'], \n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "# Define path to save model to\n",
    "path_model = 'tmp/model_6.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "    \n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit = model.fit(x=x_train, \n",
    "                y=y_train,\n",
    "                epochs=500,\n",
    "                callbacks=[early_stopper, check],\n",
    "                validation_data=(x_val, y_val),\n",
    "                verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model.load_weights(path_model)\n",
    "\n",
    "# Call function to output performance specs and graphs\n",
    "show_model_performance(model, x_val, y_val, fit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XAOemvb0D4s"
   },
   "source": [
    "#### Add Dropout to top Convolutional\n",
    "The performance of the above model didn't change substantially with the additional of regularization. The below model will add Dropout layers after each pooling layer to see if they can increase performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:23:18.745412Z",
     "iopub.status.busy": "2021-07-08T01:23:18.745060Z",
     "iopub.status.idle": "2021-07-08T01:26:31.790118Z",
     "shell.execute_reply": "2021-07-08T01:26:31.789334Z",
     "shell.execute_reply.started": "2021-07-08T01:23:18.745373Z"
    },
    "id": "8_j2fmPq0D4s",
    "outputId": "d8c6babf-3c28-48ef-fba3-acf675ebd378"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter for pooling layer\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# Define hyperparameter for L2 regularization\n",
    "LAMBDA = 0.005\n",
    "\n",
    "# Instantiate sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layer with 8 nodes\n",
    "model.add(Conv2D(8, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(LAMBDA)))\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "# Add convolutional layer with 16 nodes\n",
    "model.add(Conv2D(16, activation='relu',\n",
    "                 kernel_size=7,\n",
    "                 padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(LAMBDA)))\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "# Add convolutional layer with 32 nodes\n",
    "model.add(Conv2D(32, activation='relu',\n",
    "                 kernel_size=7,  \n",
    "                 padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(LAMBDA)))\n",
    "# Add pooling layer after convolutional\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "# Flatten input data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layer for activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='SGD',\n",
    "              metrics=['accuracy'], \n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "# Define path to save model to\n",
    "path_model = 'tmp/model_7.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "    \n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit = model.fit(x=x_train, \n",
    "                y=y_train,\n",
    "                epochs=500,\n",
    "                callbacks=[early_stopper, check],\n",
    "                validation_data=(x_val, y_val),\n",
    "                verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model.load_weights(path_model)\n",
    "\n",
    "\n",
    "# Define path to save image of training performance across epochs\n",
    "path = IMG_PATH+'performance_over_epochs'\n",
    "\n",
    "# Call function to output performance specs and graphs\n",
    "show_model_performance(model, x_val, y_val, fit, plot_path=path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDMpnfIN0D4t"
   },
   "source": [
    "##### The top performer\n",
    "After looking at each of the printed performance metrics for the above model, it appears to perform better than all predecessors. It is accordingly selected as the top performing model and will be applied to the Test dataset below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:26:33.383344Z",
     "iopub.status.busy": "2021-07-08T01:26:33.382981Z",
     "iopub.status.idle": "2021-07-08T01:26:33.387988Z",
     "shell.execute_reply": "2021-07-08T01:26:33.386935Z",
     "shell.execute_reply.started": "2021-07-08T01:26:33.383304Z"
    },
    "id": "NT45-gxj0D4t"
   },
   "outputs": [],
   "source": [
    "# Copy the model and fit from the preceding model since it was\n",
    "# determined to be the best model\n",
    "model_top = model\n",
    "fit_top = fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yWhfAsC0D4t"
   },
   "source": [
    "## Step 4. Evaluation\n",
    "Now that the top performing model has been selected, it will be retrained using both *train* and *validation* datasets before being tested on the withheld, previously untouched *test* dataset. Note that this same process is repeated for the FSM in order to compare performance improvements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC9A4fg10D4t"
   },
   "source": [
    "##### Train FSM on full dataset (Training and Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:26:33.389783Z",
     "iopub.status.busy": "2021-07-08T01:26:33.389398Z",
     "iopub.status.idle": "2021-07-08T01:27:30.953977Z",
     "shell.execute_reply": "2021-07-08T01:27:30.953034Z",
     "shell.execute_reply.started": "2021-07-08T01:26:33.389745Z"
    },
    "id": "lPX0QMSf0D4t"
   },
   "outputs": [],
   "source": [
    "# Define path to save model to\n",
    "path_model = 'tmp/final_model_fsm.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "    \n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit_fsm = model_fsm.fit(x=np.concatenate([x_train, x_val], axis=0), \n",
    "                y=np.concatenate([y_train, y_val], axis=0),\n",
    "                epochs=500,\n",
    "                callbacks=[early_stopper, check],\n",
    "                validation_data=(x_val, y_val),\n",
    "                verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model_fsm.load_weights(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhF4eL8M0D4t"
   },
   "source": [
    "##### Train Top Model on full dataset (Training and Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:27:30.957858Z",
     "iopub.status.busy": "2021-07-08T01:27:30.957589Z",
     "iopub.status.idle": "2021-07-08T01:32:23.926738Z",
     "shell.execute_reply": "2021-07-08T01:32:23.925753Z",
     "shell.execute_reply.started": "2021-07-08T01:27:30.957831Z"
    },
    "id": "Yt_EaYfr0D4t",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define path to save model to\n",
    "path_model = 'tmp/final_model_top.h5'\n",
    "\n",
    "# Delete old saved models at designated location\n",
    "if os.path.exists(path_model):\n",
    "    os.remove(path_model)\n",
    "\n",
    "# Define callback for best performing model\n",
    "check = ModelCheckpoint(path_model,save_best_only=True)\n",
    "\n",
    "# Fit model on training data, using callbacks and validation\n",
    "fit_top = model_top.fit(x=np.concatenate([x_train, x_val], axis=0), \n",
    "                y=np.concatenate([y_train, y_val], axis=0),\n",
    "                epochs=500,\n",
    "                callbacks=[early_stopper, check],\n",
    "                validation_data=(x_val, y_val),\n",
    "                verbose=0)\n",
    "\n",
    "# Load the top performing model from Checkpoint callback\n",
    "model_top.load_weights(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mwh2Q5Yn0D4u"
   },
   "source": [
    "### Measure performance on Test data\n",
    "Now that the FSM and top model are fully trained, they are evaluated below on the *test* data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QXUPfkj0D4u"
   },
   "source": [
    "##### First Simple Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:32:23.930395Z",
     "iopub.status.busy": "2021-07-08T01:32:23.930114Z",
     "iopub.status.idle": "2021-07-08T01:32:25.614242Z",
     "shell.execute_reply": "2021-07-08T01:32:25.613461Z",
     "shell.execute_reply.started": "2021-07-08T01:32:23.930367Z"
    },
    "id": "PkpFHUOu0D4u",
    "outputId": "8011ebfb-66e3-4e3c-faa9-1ce2addeca17"
   },
   "outputs": [],
   "source": [
    "show_model_performance(model_fsm, x_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NQWdamQ0D4u"
   },
   "source": [
    "##### Top Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:32:25.616415Z",
     "iopub.status.busy": "2021-07-08T01:32:25.615999Z",
     "iopub.status.idle": "2021-07-08T01:32:27.436019Z",
     "shell.execute_reply": "2021-07-08T01:32:27.435144Z",
     "shell.execute_reply.started": "2021-07-08T01:32:25.616376Z"
    },
    "id": "hjqRkTiG0D4u",
    "outputId": "0595ef15-33f7-439b-c7c2-ed451e4735c6"
   },
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX FOR TEST DATA, ***TOP MODEL***\n",
    "path = IMG_PATH+'best_model_confusion_matrix'\n",
    "show_model_performance(model_top, x_test, y_test, plot_path=path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dmcsfha_0D4u"
   },
   "source": [
    "## Step 5. Conclusion\n",
    "Below is a comparison of the performance metrics for the baseline, first-simple and final models. \n",
    "\n",
    "#### Baseline performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:32:27.437700Z",
     "iopub.status.busy": "2021-07-08T01:32:27.437429Z",
     "iopub.status.idle": "2021-07-08T01:32:27.473967Z",
     "shell.execute_reply": "2021-07-08T01:32:27.473191Z",
     "shell.execute_reply.started": "2021-07-08T01:32:27.437674Z"
    },
    "id": "mkhuK01v0D4u",
    "outputId": "63c34afa-b120-40bb-a4c7-e4de42637a4c"
   },
   "outputs": [],
   "source": [
    "preds = baseline_model(y_test)\n",
    "truth = y_test[:, 1]\n",
    "acc_pre_rec_f1(truth, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kYcU8Ct0D4v"
   },
   "source": [
    "#### First simple model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:32:27.475397Z",
     "iopub.status.busy": "2021-07-08T01:32:27.475060Z",
     "iopub.status.idle": "2021-07-08T01:32:28.133375Z",
     "shell.execute_reply": "2021-07-08T01:32:28.132553Z",
     "shell.execute_reply.started": "2021-07-08T01:32:27.475363Z"
    },
    "id": "aIrCqxjr0D4v",
    "outputId": "8b388163-af43-404e-d60c-b564d5c55088"
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(model_fsm.predict(x_test), axis=-1)\n",
    "truth = (y_test[:, 1]==1).astype('int')\n",
    "acc_pre_rec_f1(truth, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyX5cv-G0D4v"
   },
   "source": [
    "#### Best model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-08T01:32:28.135171Z",
     "iopub.status.busy": "2021-07-08T01:32:28.134797Z",
     "iopub.status.idle": "2021-07-08T01:32:28.871549Z",
     "shell.execute_reply": "2021-07-08T01:32:28.870677Z",
     "shell.execute_reply.started": "2021-07-08T01:32:28.135129Z"
    },
    "id": "UYb4vV7W0D4v",
    "outputId": "eac34c8e-e0db-4535-c2df-6d7a29215078"
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(model_top.predict(x_test), axis=-1)\n",
    "truth = (y_test[:, 1]==1).astype('int')\n",
    "acc_pre_rec_f1(truth, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jas6kEFb0D4w"
   },
   "source": [
    "As can be seen above, there is noteworthy improvement across the model development process. The best performing model does in fact enable results that are non-trivially better than the first simple model. However, it is also worth noting that for an application where speed was prioritized over performance, the first simple model is sufficiently viable. The training time was substantially lower, giving it merit of its own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TilxPOsp0D4w"
   },
   "source": [
    "### Future improvements\n",
    "Although the above models are high performers, there is always room for improvement or further exploration. Some of those possibilities are discussed below.\n",
    "\n",
    "- **Increase image resolution:** currently, photos are downsampled from roughly 800x1200 pixels to roughly 200x200 pixels. This choice was made to enable the script to run without crashing due to memory shortages. This issue is inherent to the methodology used to the images being stored in memory as a numpy array. However, analyzing these images in \"batches\" would eliminate the need to store an array in memory. As a result, more data could be analyzed. With more data, presumably the model could be more effective. \n",
    "- **Hyperparameter grid searches:** currently, ideal hyperparameters were selected based on some fine tuning and outside research. Note that not all iterations of those models are included in this notebook so that the notebook can run in a reasomnable amount of time. An exhaustive hyperparameter optimization is necessary to truly identify the top performing model, but that will be left for future analyses with more computational resources. \n",
    "- **Expandsion of scope:** Expansion to further x-ray image recognition datasets provided by the same academic researchers who provided this dataset (see README for citation). Testing these models on additional datasets could be an interesting project, and could provide insight regarding the broad applicability of the models at hand. \n",
    "\n",
    "### Citations\n",
    "(1) Kermany D, Goldbaum M, Cai W et al. Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning. Cell. 2018; 172(5):1122-1131. doi:10.1016/j.cell.2018.02.010."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "final-notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
